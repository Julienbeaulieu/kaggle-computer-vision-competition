{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Notebook widget for interactive exploration\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import cv2 as cv\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from src.data.load_datasets import load_label_csv, load_data_train, load_data_val\n",
    "from src.data.load_datasets import load_grapheme_classes\n",
    "from src.data.grapheme_composition import encode_grapheme\n",
    "from src.data.grapheme_composition import get_components\n",
    "from src.data.data_labels import get_labels\n",
    "from src.data.data_labels import filter_label_df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .ENV path. \n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Get Env variable on the pathing. \n",
    "\n",
    "PATH_DATA_INTERIM=os.getenv(\"PATH_DATA_INTERIM\")\n",
    "PATH_DATA_RAW=os.getenv(\"PATH_DATA_RAW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeling data for decoding purpose\n",
    "grapheme_train = load_label_csv()\n",
    "# Load training data\n",
    "data_train = load_data_train()\n",
    "# Load validation data\n",
    "data_val = load_data_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the class data for decoding purpose\n",
    "grapheme_classes = load_grapheme_classes()\n",
    "grapheme_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = data_train[2][1]\n",
    "list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_components(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_train = get_labels(data_train)\n",
    "df_label_val = get_labels(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_root = grapheme_classes[grapheme_classes.component_type.eq(\"grapheme_root\")]\n",
    "total_vowel = grapheme_classes[grapheme_classes.component_type.eq(\"vowel_diacritic\")]\n",
    "total_consonant = grapheme_classes[grapheme_classes.component_type.eq(\"consonant_diacritic\")]\n",
    "\n",
    "len(total_root)\n",
    "total_vowel\n",
    "total_consonant\n",
    "\n",
    "@interact\n",
    "def show_count(index_root=(0, len(total_root)-1, 1), \n",
    "               index_vowel=(0, len(total_vowel)-1, 1), \n",
    "               index_consonant=(0, len(total_consonant)-1, 1)):            \n",
    "    \n",
    "    subset_train = filter_label_df_index(df_label_train, index_root, index_vowel,index_consonant)    \n",
    "    subset_val = filter_label_df_index(df_label_val, index_root, index_vowel,index_consonant)    \n",
    "    encode_grapheme(index_root, index_vowel,index_consonant)\n",
    "    print(f\"There are a total of {len(subset_train)} cases in the training AND {len(subset_val)} cases in validation data set.\")\n",
    "    print(f\"Proportion of {len(subset_train)/len(df_label_train)*100}% in the training AND {len(subset_val)/len(df_label_val)*100}% in validation data set.\")\n",
    "    #return (subset_train, subset_val)\n",
    "    \n",
    "    # Exit early if no images. \n",
    "    if len(subset_train)==0 or len(subset_val)==0:\n",
    "        return\n",
    "    \n",
    "    @interact\n",
    "    def show_image(train_index=(0,len(subset_train)-1,1), val_index=(0,len(subset_val)-1,1)):    \n",
    "        index_train=subset_train[train_index]\n",
    "        index_val=subset_val[val_index]\n",
    "        # Load the training image index    \n",
    "        img_train = Image.fromarray(data_train[index_train][0], \"L\")\n",
    "        img_val = Image.fromarray(data_val[index_val][0], \"L\")\n",
    "\n",
    "        #get_components(list_labels)\n",
    "\n",
    "        # Compose into the composite array laytout\n",
    "        f, axarr = plt.subplots(1,2)\n",
    "        axarr[0].imshow(img_train, cmap='gray')\n",
    "        axarr[0].set_title(\"Training Set\")\n",
    "        axarr[1].imshow(img_val, cmap='gray')    \n",
    "        axarr[1].set_title(\"Validation Set\")\n",
    "        f.set_size_inches(18.5, 10.5)\n",
    "        #f.suptitle(\"Raw Grapheme Images\", fontsize=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
